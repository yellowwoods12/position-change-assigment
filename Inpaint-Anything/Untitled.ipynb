{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1291769-6c61-4cd8-86e9-f070814b9dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 11:17:16.737874: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-16 11:17:17.711851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectron v2 is not installed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sam_segment import predict_masks_with_sam\n",
    "from lama_inpaint import inpaint_img_with_lama\n",
    "from utils import load_img_to_array, save_array_to_img, dilate_mask, \\\n",
    "    show_mask, show_points, get_clicked_point\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527a092-0890-4320-b84f-7a39fdb7721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_args(parser):\n",
    "    parser.add_argument(\n",
    "        \"--input_img\", type=str, required=True,\n",
    "        help=\"Path to a single input img\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--coords_type\", type=str, required=True,\n",
    "        default=\"key_in\", choices=[\"click\", \"key_in\"], \n",
    "        help=\"The way to select coords\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_coords\", type=float, nargs='+', required=True,\n",
    "        help=\"The coordinate of the point prompt, [coord_W coord_H].\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_labels\", type=int, nargs='+', required=True,\n",
    "        help=\"The labels of the point prompt, 1 or 0.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dilate_kernel_size\", type=int, default=None,\n",
    "        help=\"Dilate kernel size. Default: None\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\", type=str, required=True,\n",
    "        help=\"Output path to the directory with results.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sam_model_type\", type=str,\n",
    "        default=\"vit_h\", choices=['vit_h', 'vit_l', 'vit_b', 'vit_t'],\n",
    "        help=\"The type of sam model to load. Default: 'vit_h\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sam_ckpt\", type=str, required=True,\n",
    "        help=\"The path to the SAM checkpoint to use for mask generation.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lama_config\", type=str,\n",
    "        default=\"./lama/configs/prediction/default.yaml\",\n",
    "        help=\"The path to the config file of lama model. \"\n",
    "             \"Default: the config of big-lama\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lama_ckpt\", type=str, required=True,\n",
    "        help=\"The path to the lama checkpoint.\",\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Example usage:\n",
    "    python remove_anything.py \\\n",
    "        --input_img FA_demo/FA1_dog.png \\\n",
    "        --coords_type key_in \\\n",
    "        --point_coords 750 500 \\\n",
    "        --point_labels 1 \\\n",
    "        --dilate_kernel_size 15 \\\n",
    "        --output_dir ./results \\\n",
    "        --sam_model_type \"vit_h\" \\\n",
    "        --sam_ckpt sam_vit_h_4b8939.pth \\\n",
    "        --lama_config lama/configs/prediction/default.yaml \\\n",
    "        --lama_ckpt big-lama \n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    setup_args(parser)\n",
    "    args = parser.parse_args(sys.argv[1:])\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    if args.coords_type == \"click\":\n",
    "        latest_coords = get_clicked_point(args.input_img)\n",
    "    elif args.coords_type == \"key_in\":\n",
    "        latest_coords = args.point_coords\n",
    "    img = load_img_to_array(args.input_img)\n",
    "\n",
    "    masks, _, _ = predict_masks_with_sam(\n",
    "        img,\n",
    "        [latest_coords],\n",
    "        args.point_labels,\n",
    "        model_type=args.sam_model_type,\n",
    "        ckpt_p=args.sam_ckpt,\n",
    "        device=device,\n",
    "    )\n",
    "    masks = masks.astype(np.uint8) * 255\n",
    "\n",
    "    # dilate mask to avoid unmasked edge effect\n",
    "    if args.dilate_kernel_size is not None:\n",
    "        masks = [dilate_mask(mask, args.dilate_kernel_size) for mask in masks]\n",
    "\n",
    "    # visualize the segmentation results\n",
    "    img_stem = Path(args.input_img).stem\n",
    "    out_dir = Path(args.output_dir) / img_stem\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for idx, mask in enumerate(masks):\n",
    "        # path to the results\n",
    "        mask_p = out_dir / f\"mask_{idx}.png\"\n",
    "        img_points_p = out_dir / f\"with_points.png\"\n",
    "        img_mask_p = out_dir / f\"with_{Path(mask_p).name}\"\n",
    "\n",
    "        # save the mask\n",
    "        save_array_to_img(mask, mask_p)\n",
    "\n",
    "        # save the pointed and masked image\n",
    "        dpi = plt.rcParams['figure.dpi']\n",
    "        height, width = img.shape[:2]\n",
    "        plt.figure(figsize=(width/dpi/0.77, height/dpi/0.77))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        show_points(plt.gca(), [latest_coords], args.point_labels,\n",
    "                    size=(width*0.04)**2)\n",
    "        plt.savefig(img_points_p, bbox_inches='tight', pad_inches=0)\n",
    "        show_mask(plt.gca(), mask, random_color=False)\n",
    "        plt.savefig(img_mask_p, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "    # inpaint the masked image\n",
    "    for idx, mask in enumerate(masks):\n",
    "        mask_p = out_dir / f\"mask_{idx}.png\"\n",
    "        img_inpainted_p = out_dir / f\"inpainted_with_{Path(mask_p).name}\"\n",
    "        img_inpainted = inpaint_img_with_lama(\n",
    "            img, mask, args.lama_config, args.lama_ckpt, device=device)\n",
    "        save_array_to_img(img_inpainted, img_inpainted_p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "sam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
